---
title: "3D Gaussian Splatting as Markov Chain Monte Carlo"
subtitle: "NeurIPS 2024"
author: "Minsu Kim"
date: "2025.11.28"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{css, echo=FALSE}
.title-slide .remark-slide-number {
  display: none;
}

.contents-list {
  font-size: 30px;
  font-family: 'Trebuchet MS', sans-serif;
  line-height: 1.5;
}

.main-text {
  font-size: 30px;
  font-family: 'Trebuchet MS', sans-serif;
  line-height: 1.5;
}

.remark-slide-number {
  font-size: 16px;
  bottom: 40px;
  right: 10px;
}

.remark-slide-content:not(.title-slide)::before {
  content: "";
  position: absolute;
  bottom: 8px;
  right: 10px;
  width: 80px;
  height: 30px;
  background: url('lab_logo.jpg') no-repeat center;
  background-size: contain;
}
```

<!-- class: title-slide
count: false -->
# Contents

.contents-list[
1. Introduction
2. Method
3. Experiments
4. Conclusion
]

---

# Introduction

### Neural Rendering의 발전

- **Neural Radiance Fields (NeRF)**
  - 신경망을 통한 implicit modeling으로 인상적인 결과 제공하지만 렌더링 속도가 느림

- **3D Gaussian Splatting (3DGS)**
  - NeRF 대비 빠른 속도와 효율성
  - 고품질 이미지를 짧은 시간에 렌더링 가능
  - 하지만 몇 가지 한계 존재
      - 수작업으로 설계된 cloning/splitting 휴리스틱에 의존
      - Gaussian들을 clone, split, prune하는 복잡한 규칙
      - 정기적으로 opacity를 리셋하여 floater 제거 필요
      - 좋은 초기 point cloud에 크게 의존
      - Gaussian 개수를 미리 추정하기 어려움
      - 메모리/계산 예산 제어가 어려움

---

# Introduction

- 따라서, 이러한 문제를 해결해 보고자, 3D Gaussian을 MCMC(Markov Chain Monte Carlo) 샘플로 재해석
  - 3D Gaussian들을 probability distribution에서 추출된 **random samples**로 간주
- 이렇게 하면, 기존의 Heuristic한 adaptive density control 방법을 MCMC의 state transition으로 대체 가능


- Markov Chain?
  - Markov Chain을 사용하여 샘플링하며, 각 상태는 이전 상태에만 의존
  - 현재 상태에서 다음 상태는 state transition kernel에 의해 결정
      $$x_{t+1} \sim T(x_{t+1} | x_t)$$
  - Markov property:
      $$\quad p(x_{t+1} | x_t, x_{t-1}, \dots) = p(x_{t+1} | x_t)$$

- Monte Carlo?
  - 직접 적분이 어려운 확률 분포에서 랜덤 샘플링하여 근사적 해를 구하는 방법
  - 즉, 랜덤 샘플들의 평균으로 기대값을 근사

---

# Method

  - **3D Gaussian Splatting as Markov Chain Monte Carlo**
  - 


---

**'Cloning' 전략으로 Gaussian 재배치**

- **Dead Gaussians** (낮은 opacity) → **Live Gaussians** 위치로 이동
- 렌더링에 미치는 영향 최소화
- Clone된 Gaussian들이 이전과 동일한 이미지를 렌더링하도록 구성

--

**L1 Regularization**

- Gaussian의 효율적 사용을 장려
- Opacity와 scale 모두에 적용
- 불필요한 Gaussian은 자연스럽게 '사라지도록' 유도

---

# Introduction

## Main Contributions

✅ **3DGS와 MCMC sampling의 연결 발견** → 더 간단한 최적화

✅ **Heuristics를 원칙적인 relocation 전략으로 대체**

✅ **Parsimonious use를 위한 regularizer 도입**

✅ **초기화에 대한 robustness 향상**
   - Random initialization 또는 SfM points 모두 가능

✅ **더 높은 렌더링 품질 제공**
   - NeRF Synthetic, MipNeRF 360, Tank & Temples, Deep Blending, OMMO 등에서 검증